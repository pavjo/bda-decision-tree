{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"Abominable_Data_HW_LABELED_TRAINING_DATA__v772_2231.csv\")\n",
    "\n",
    "# quantising the data\n",
    "def quant(v):\n",
    "    return round(v*2)/2\n",
    "\n",
    "data[\"Age\"] = data[\"Age\"].round()\n",
    "data[\"Ht\"] = data[\"Ht\"].round()\n",
    "data[\"TailLn\"] = data[\"TailLn\"].apply(quant)\n",
    "data[\"HairLn\"] = data[\"HairLn\"].apply(quant)\n",
    "data[\"BangLn\"] = data[\"BangLn\"].apply(quant)\n",
    "data[\"Reach\"] = data[\"Reach\"].apply(quant)\n",
    "\n",
    "# create new features\n",
    "data[\"Shagginess\"] = data[\"HairLn\"] - data[\"BangLn\"]\n",
    "data[\"ApeFactor\"] = data[\"Reach\"] - data[\"Ht\"]\n",
    "\n",
    "\n",
    "### create a test suite of length 8 with attribute Age. -- Test Suite B\n",
    "\n",
    "# greater than 100 bhuttan and less than assam\n",
    "x = data[(data[\"Ht\"] <= 100) & (data[\"ClassID\"] == -1 )].head(4)\n",
    "y = data[(data[\"Ht\"] > 100) & (data[\"ClassID\"] == 1 )].head(4)\n",
    "\n",
    "z = pd.concat([x,y])\n",
    "z.to_csv(\"Test_Suite_A_height.csv\", index = False)\n",
    "\n",
    "\n",
    "# greater than 30 belong to assam and less than 30 belong to 1\n",
    "x = data[(data[\"Age\"] <= 30) & (data[\"ClassID\"] == 1 )].head(4)\n",
    "y = data[(data[\"Age\"] > 30) & (data[\"ClassID\"] == 1 )].head(4)\n",
    "z = pd.concat([x,y])\n",
    "z.to_csv(\"Test_Suite_B_age.csv\", index = False)\n",
    "\n",
    "# create a test suite of length 8 with attribute tail length. -- Test Suite C \n",
    "x = data[(data[\"TailLn\"] <= 10) & (data[\"ClassID\"] == 1 )].head(4)\n",
    "y = data[(data[\"TailLn\"] > 10) & (data[\"ClassID\"] == -1 )].head(4)\n",
    "z = pd.concat([x,y])\n",
    "z.to_csv(\"Test_Suite_C_tail.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best attribute with its best threshold.\n",
    "\n",
    "data = pd.read_csv(\"Test_Suite_B_age.csv\")\n",
    "attributes = list(data.columns[:6])\n",
    "\n",
    "def find_entropy(noden):\n",
    "    \"\"\"\n",
    "    Calcultes entropy for the given node\n",
    "    \"\"\"\n",
    "    e = 0\n",
    "    for i in noden:\n",
    "        pv = (i/np.sum(noden))\n",
    "        if pv == 0:\n",
    "            e += 0\n",
    "        else:\n",
    "            e += (pv * np.log2(pv))\n",
    "    return -e\n",
    "\n",
    "def Fgain_ratio(noden,pe):\n",
    "    \"\"\"\n",
    "    Calculates the information gain for the give data.\n",
    "    \"\"\"\n",
    "    s = 0 # average entropy of the set; second term in the gain formula\n",
    "    spliti = 0 # split info\n",
    "    parent_entropy = find_entropy(pe) # entropy of the entire set\n",
    "    \n",
    "    for i in noden:\n",
    "        niBYnt = (np.sum(i)/np.sum(noden))\n",
    "        s +=  niBYnt * find_entropy(i) \n",
    "        spliti += niBYnt * np.log2(niBYnt)\n",
    "    spliti = -spliti\n",
    "    information_gain = parent_entropy - s\n",
    "    information_gain_Ratio = information_gain/spliti\n",
    "    # print(parent_entropy, s, information_gain,spliti,information_gain_Ratio )\n",
    "    # print(\"igr\", information_gain_Ratio)\n",
    "    return information_gain_Ratio\n",
    "\n",
    "dict =  {}\n",
    "for attribute in attributes:\n",
    "    # print(attribute)\n",
    "    best_igr = -1.0\n",
    "    pe = [len(data[data[\"ClassID\"] == 1]), len(data[data[\"ClassID\"] == -1])]\n",
    "    for threshold in np.arange(data[attribute].min(), data[attribute].max()+1):\n",
    "        # splitting the attribute on the given threshold.\n",
    "        nodeL = data[data[attribute] <= threshold] \n",
    "        nodeR = data[data[attribute] > threshold]\n",
    "        nodeL_splits = [len(nodeL[nodeL[\"ClassID\"] == 1]), len(nodeL[nodeL[\"ClassID\"] == -1])]\n",
    "        nodeR_splits = [len(nodeR[nodeR[\"ClassID\"] == 1]), len(nodeR[nodeR[\"ClassID\"] == -1])]\n",
    "        x = [nodeL_splits, nodeR_splits]\n",
    "        igr = Fgain_ratio(x, pe)\n",
    "        if igr > best_igr:\n",
    "            best_igr = igr\n",
    "            best_thres = threshold\n",
    "    dict[attribute] = [best_thres, best_igr]\n",
    "print(dict)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
